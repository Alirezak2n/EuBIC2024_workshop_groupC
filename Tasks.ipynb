{"cells":[{"cell_type":"markdown","metadata":{"id":"1gO1eIT3gOn-"},"source":["# Fragment ion intensities Prediction\n","\n","This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU."]},{"cell_type":"markdown","metadata":{"id":"YA2mURt3gOoC"},"source":["### Task 1: Learning Rate\n","We delve into the pivotal role of the learning rate in training neural networks, a crucial factor impacting model performance. Your objective is to identify the ideal learning rate for our dataset. This entails experimenting with various values. These values directly influence how the model adjusts its parameters during training, determining its overall performance. Explore how changing learning rate influences loss dynamics and other metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qi8FnfcngOoD"},"outputs":[],"source":["# install the mlomix package in the current environment using pip\n","\n","!python -m pip install -q dlomix==0.0.4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkYM9CawgOoE"},"outputs":[],"source":["!python -m pip install -q wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"omUXT4aHgOoF"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import dlomix\n","from dlomix.models import PrositIntensityPredictor\n","import tensorflow as tf\n","from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n","tf.get_logger().setLevel('ERROR')\n","\n","import wandb\n","from wandb.keras import WandbCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dihspwI6gOoG"},"outputs":[],"source":["# enter project name for weights and biases\n","project_name = 'learning_rate'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcaIt6VJgOoG"},"outputs":[],"source":["from dlomix.data import IntensityDataset\n","\n","TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/Intensity/proteomeTools_train_val.csv'\n","BATCH_SIZE = 64\n","\n","int_data = IntensityDataset(data_source=TRAIN_DATAPATH, seq_length=30,\n","                            collision_energy_col='collision_energy', batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5kn_3R4gOoH"},"outputs":[],"source":["# Enter weights and biases run name. Make sure that different learning rates have different run names.\n","wandb.init(project=project_name, name=)\n","\n","# create model\n","model = PrositIntensityPredictor(seq_length=30)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=)\n","\n","# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n","model.compile(optimizer=optimizer,\n","              loss=masked_spectral_distance, metrics=[masked_pearson_correlation_distance, 'mean_absolute_error', 'mse'])\n","\n","history = model.fit(int_data.train_data, validation_data=int_data.val_data,\n","                    epochs=15, callbacks=[WandbCallback(save_model=False)])\n","\n","\n","# Mark the run as finished\n","wandb.finish()"]},{"cell_type":"markdown","source":["### Task 2: Model Architecture\n","In this task, we are going to change model architecture (embedding output dimensionality and encoder layer type) to explore how this would change the model performance. The parameter `embedding_dim` is the size of the vector representing each amino acid, the higher it is, the more representative power it has. The `recurrent_layers_sizes` is the number of units in the two GRU layers in the model encoder, the higher it is, the more parameters the model will have and that can help with detecting complex patterns but can also lead to overfitting. Explore how changing them would change the model performance. Change one thing at a time to see how it will affect the model."],"metadata":{"id":"kqGM6viGsgnq"}},{"cell_type":"code","source":["# enter project name for weights and biases\n","project_name = 'model_architecture'"],"metadata":{"id":"LyQE2yj_2-mK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Enter weights and biases run name. Make sure that different models have different run names.\n","wandb.init(project=project_name, name=)\n","\n","# create model\n","model = PrositIntensityPredictor(seq_length=30, embedding_output_dim=,\n","        recurrent_layers_sizes=)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","# compile the model  with the optimizer and the metrics we want to use, we can add our custom time-delta metric\n","model.compile(optimizer=optimizer,\n","              loss=masked_spectral_distance, metrics=[masked_pearson_correlation_distance])\n","\n","history = model.fit(int_data.train_data, validation_data=int_data.val_data,\n","                    epochs=30, callbacks=[WandbCallback(save_model=False)])\n","\n","# Mark the run as finished\n","wandb.finish()"],"metadata":{"id":"xZF1KhNesi3M"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[{"file_id":"https://github.com/wilhelm-lab/dlomix-resources/blob/main/notebooks/Intensity/tasks/1_LearningRate.ipynb","timestamp":1704793117026}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}